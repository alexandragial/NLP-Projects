{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "import random\n",
        "import numpy as np\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk.util import ngrams\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize"
      ],
      "metadata": {
        "id": "gdT0YQFnMVvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download Project Gutenberg\n",
        "nltk.download('gutenberg')\n",
        "\n",
        "# Download package for tokenization\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "id": "VfBklCxBMars"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = gutenberg.fileids()\n",
        "print(\"Filenames:\", files)\n",
        "print(\"Number of files:\", len(files))"
      ],
      "metadata": {
        "id": "XaDPX7W4NCvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select 10 books\n",
        "random.seed(0)\n",
        "books = random.sample(files, 10)\n",
        "print(\"Books selected:\", books)"
      ],
      "metadata": {
        "id": "16x5oir4NFRO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = list()\n",
        "vocab = list()\n",
        "\n",
        "for i in range(len(books)):\n",
        "\n",
        "  # Useful information for the books\n",
        "  print(\"Name:\", books[i])\n",
        "  print(\"Number of tokens:\", len(gutenberg.words(books[i])))\n",
        "  print()\n",
        "\n",
        "  # Tokenization of sentences & words\n",
        "  sentences = (sent_tokenize(gutenberg.raw(books[i])))\n",
        "  tokens.append(word_tokenize(gutenberg.raw(books[i])))\n",
        "\n",
        "# Convert the nested list to a simple list\n",
        "tokens = [t for innerList in tokens for t in innerList]\n",
        "# Building Vocabulary\n",
        "vocab.append(sorted(set(tokens)))\n"
      ],
      "metadata": {
        "id": "zMhRctLONHgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unigrams\n",
        "unigrams = ngrams(tokens,1)\n",
        "\n",
        "freqUni = nltk.FreqDist(unigrams)\n",
        "for key,value in freqUni.items():\n",
        "    print(key,value)"
      ],
      "metadata": {
        "id": "ftXY5GrvNRIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bigrams\n",
        "bigrams = nltk.bigrams(tokens)\n",
        "\n",
        "freqBigr = nltk.FreqDist(bigrams)\n",
        "for key,value in freqBigr.items():\n",
        "    print(key,value)"
      ],
      "metadata": {
        "id": "xuLG9ZfUNR2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make a sentence using bigrams**"
      ],
      "metadata": {
        "id": "i5Pa16F_lQHt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of words in the sentence\n",
        "numberOfWords = 10\n",
        "# Convert to a list the keys of the dictionary\n",
        "listOfKeys = list()\n",
        "# Convert to a list the values of the dictionary\n",
        "listOfValues = list()\n",
        "# Words of the sentence\n",
        "words = list()\n",
        "\n",
        "for key, value in freqBigr.items():\n",
        "  listOfKeys.append(list(key))\n",
        "  listOfValues.append(value)\n",
        "\n",
        "# For sampling in trigrams\n",
        "bigramsKeys = listOfKeys\n",
        "\n",
        "# Define the first word of the sentence\n",
        "firstWord = 'the'\n",
        "previousWord = firstWord\n",
        "words.append(firstWord)\n",
        "\n",
        "while len(words) <= numberOfWords:\n",
        "  nextWordDict = dict()\n",
        "  nextWordDict[previousWord] = list()\n",
        "  for i in range(len(listOfKeys)-1):\n",
        "    for j in range(len(listOfKeys[i])-1):\n",
        "      if j == 1:\n",
        "        # Second element of bigrams\n",
        "        # Append the first element of the next bigram\n",
        "        nextWordDict[previousWord].append(listOfKeys[i+1][0])\n",
        "      if listOfKeys[i][j] == previousWord:\n",
        "        # Append all the possible next words\n",
        "        nextWordDict[previousWord].append(listOfKeys[i][j+1])\n",
        "  if len(words) == numberOfWords:\n",
        "    # The last word of the sentence\n",
        "    nextWord = \".\"\n",
        "    words.append(nextWord)\n",
        "  else:\n",
        "    nextWord = random.choice(nextWordDict[previousWord])\n",
        "    words.append(nextWord)\n",
        "    previousWord = nextWord\n",
        "\n",
        "print(\" \".join(words))"
      ],
      "metadata": {
        "id": "nydSOIw_Pbq8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Trigrams\n",
        "trigrams = nltk.trigrams(tokens)\n",
        "\n",
        "freqTrigr = nltk.FreqDist(trigrams)\n",
        "for key,value in freqTrigr.items():\n",
        "  print(key,value)"
      ],
      "metadata": {
        "id": "KbU06nI7ODr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Number of words in the sentence\n",
        "numberOfWords = 10\n",
        "# Convert to a list the keys of the dictionary\n",
        "listOfKeys = list()\n",
        "# Convert to a list the values of the dictionary\n",
        "listOfValues = list()\n",
        "# Words of the sentence\n",
        "words = list()\n",
        "\n",
        "for key, value in freqTrigr.items():\n",
        "  listOfKeys.append(list(key))\n",
        "  listOfValues.append(value)\n",
        "\n",
        "bigramsChoice = random.choice(bigramsKeys)\n",
        "firstWord = bigramsChoice[0]\n",
        "secondWord = bigramsChoice[1]\n",
        "print(bigramsChoice)\n",
        "print(bigramsChoice[0])\n",
        "print(bigramsChoice[1])"
      ],
      "metadata": {
        "id": "s64MhHxqO25j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Make a sentence using trigrams**"
      ],
      "metadata": {
        "id": "wRyb1uRulv6T"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJS44Qt0L80b",
        "outputId": "e164ea07-b1a3-4dd9-9ffb-4d883ec6bdb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
          ]
        }
      ],
      "source": [
        "#firstWord = 'I'\n",
        "#secondWord = 'have'\n",
        "previousWord1 = firstWord\n",
        "previousWord2 = secondWord\n",
        "phrase = previousWord1 + ' ' + previousWord2\n",
        "words.append(firstWord)\n",
        "words.append(secondWord)\n",
        "\n",
        "while len(words) <= numberOfWords:\n",
        "  nextWordDict = dict()\n",
        "  nextWordDict[phrase] = list()\n",
        "  for i in range(len(listOfKeys)-1):\n",
        "    for j in range(1, len(listOfKeys[i])-1):\n",
        "      if j == 2:\n",
        "        nextWordDict[phrase].append(listOfKeys[i+1][0])\n",
        "      if listOfKeys[i][j] == previousWord2 and listOfKeys[i][j-1] == previousWord1:\n",
        "        nextWordDict[phrase].append(listOfKeys[i][j+1])\n",
        "  if len(words) == numberOfWords:\n",
        "    nextWord = \".\"\n",
        "    words.append(nextWord)\n",
        "  else:\n",
        "    nextWord = random.choice(nextWordDict[phrase])\n",
        "    words.append(nextWord)\n",
        "    previousWord1 = previousWord2\n",
        "    previousWord2 = nextWord\n",
        "    phrase = previousWord1 + ' ' + previousWord2\n",
        "\n",
        "print(\" \".join(words))"
      ]
    }
  ]
}
